# app.py - BookFlix (Netflix-style Streamlit GUI)
# Generated to work with your Colab notebook artifacts.

"""
Requirements:
- streamlit
- pandas
- numpy
- scikit-learn
- requests
- pillow

Place your artifacts (generated by your notebook) in an `artifacts/` folder next to this file:
- artifacts/book_name.pkl       (list of titles or pd.Series)
- artifacts/book_pivot.pkl      (user-item pivot DataFrame)
- artifacts/final_rating.pkl    (DataFrame with columns: title, num_rating, avg_rating)
- artifacts/similarity.pkl OR artifacts/model.pkl (optional precomputed similarity or KNN model)

Fallback: if the artifacts are missing, the app will try to build them from raw CSVs placed in a `data/` folder:
- data/BX-Books.csv
- data/BX-Book-Ratings.csv

Columns expected in BX-Books.csv: 'Book-Title', 'Book-Author', 'Image-URL-M' (common in BX dataset).
"""

import streamlit as st
import pandas as pd
import numpy as np
from pathlib import Path
import pickle
import requests
from io import BytesIO
from PIL import Image
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.neighbors import NearestNeighbors
import os

# ----- Config -----
st.set_page_config(page_title="BookFlix", layout="wide")
ARTIFACTS = Path("artifacts")
DATA_DIR = Path("data")
ARTIFACTS.mkdir(exist_ok=True)

# Expected filenames
BOOK_NAMES_PKL = ARTIFACTS / "book_name.pkl"
PIVOT_PKL = ARTIFACTS / "book_pivot.pkl"
FINAL_PKL = ARTIFACTS / "final_rating.pkl"
SIM_PKL = ARTIFACTS / "similarity.pkl"
MODEL_PKL = ARTIFACTS / "model.pkl"
BOOKS_CSV = DATA_DIR / "BX-Books.csv"
RATINGS_CSV = DATA_DIR / "BX-Book-Ratings.csv"

PLACEHOLDER = "https://via.placeholder.com/128x192.png?text=No+Cover"

# ----- Helpers -----
@st.cache_data
def safe_load_pickle(path):
    try:
        with open(path, "rb") as f:
            return pickle.load(f)
    except Exception:
        return None

@st.cache_data
def try_fetch_image(url):
    if not isinstance(url, str) or url.strip() == "":
        return None
    try:
        resp = requests.get(url, timeout=5)
        img = Image.open(BytesIO(resp.content))
        return img
    except Exception:
        return None

def recommend_from_similarity(title, sim, pivot, k=5):
    if sim is None:
        return []
    titles = list(pivot.columns)
    if title not in titles:
        return []
    idx = titles.index(title)
    distances = list(enumerate(sim[idx]))
    distances = sorted(distances, key=lambda x: x[1], reverse=True)
    recs = [titles[i] for i,_ in distances[1:k+1]]
    return recs

def recommend_with_knn(title, model, pivot, k=5):
    titles = list(pivot.columns)
    if title not in titles:
        return []
    idx = titles.index(title)
    # model expects item vectors (titles x features)
    try:
        distances, indices = model.kneighbors(pivot.T.iloc[idx:idx+1, :], n_neighbors=k+1)
        recs = [titles[i] for i in indices[0] if i != idx]
        return recs[:k]
    except Exception:
        return []

@st.cache_data
def build_from_csvs(books_csv, ratings_csv):
    # Read using semicolon separator (common for BX dataset)
    try:
        books = pd.read_csv(books_csv, sep=';', encoding='latin-1', low_memory=False)
    except Exception:
        books = pd.read_csv(books_csv, encoding='latin-1', low_memory=False)
    try:
        ratings = pd.read_csv(ratings_csv, sep=';', encoding='latin-1', low_memory=False)
    except Exception:
        ratings = pd.read_csv(ratings_csv, encoding='latin-1', low_memory=False)

    # Normalise column names
    books.columns = [c.strip() for c in books.columns]
    ratings.columns = [c.strip() for c in ratings.columns]

    # Find title col
    title_col = None
    for c in books.columns:
        if 'title' in c.lower():
            title_col = c
            break
    if title_col is None:
        books['Book-Title'] = books.iloc[:,0].astype(str)
        title_col = 'Book-Title'

    # rating columns
    user_col = None
    rating_col = None
    for c in ratings.columns:
        lc = c.lower()
        if 'user' in lc:
            user_col = c
        if 'rating' in lc:
            rating_col = c
    if user_col is None:
        user_col = ratings.columns[0]
    if rating_col is None:
        ratings['Rating'] = 1
        rating_col = 'Rating'

    # merge on ISBN if present
    join_b = None
    join_r = None
    for c in books.columns:
        if 'isbn' in c.lower():
            join_b = c
            break
    for c in ratings.columns:
        if 'isbn' in c.lower() or 'isbn' in c.lower():
            join_r = c
            break

    merged = ratings.copy()
    if join_b and join_r:
        merged = ratings.merge(books[[join_b, title_col]], left_on=join_r, right_on=join_b, how='left')
        merged.rename(columns={title_col: 'title'}, inplace=True)
    elif 'title' in ratings.columns:
        merged = ratings.rename(columns={'title':'title'})
    else:
        # attempt to map using book id
        merged['title'] = None

    merged = merged[merged['title'].notnull()]

    merged['rating'] = merged[rating_col]

    final_rating = merged.groupby('title').agg({'rating':['count','mean']})
    final_rating.columns = ['num_rating','avg_rating']
    final_rating = final_rating.reset_index().rename(columns={'title':'title'})

    # pivot
    pivot = merged.pivot_table(index=user_col, columns='title', values='rating', aggfunc='mean').fillna(0)

    # similarity
    try:
        sim = cosine_similarity(pivot.T)
    except Exception:
        sim = None

    # save pickles
    try:
        pickle.dump(list(final_rating['title'].values), open(BOOK_NAMES_PKL,'wb'))
        pickle.dump(pivot, open(PIVOT_PKL,'wb'))
        pickle.dump(final_rating, open(FINAL_PKL,'wb'))
        if sim is not None:
            pickle.dump(sim, open(SIM_PKL,'wb'))
    except Exception as e:
        st.warning(f"Could not save artifacts: {e}")

    return list(final_rating['title'].values), pivot, final_rating, sim

# ----- Load artifacts -----
book_names = safe_load_pickle(BOOK_NAMES_PKL)
pivot = safe_load_pickle(PIVOT_PKL)
final_rating = safe_load_pickle(FINAL_PKL)
sim_matrix = safe_load_pickle(SIM_PKL)
model = safe_load_pickle(MODEL_PKL)

# If missing, try build from CSVs
if (book_names is None or pivot is None) and BOOKS_CSV.exists() and RATINGS_CSV.exists():
    book_names, pivot, final_rating, sim_matrix = build_from_csvs(BOOKS_CSV, RATINGS_CSV)

# If still missing, show message and stop
if book_names is None or pivot is None:
    st.title("BookFlix - GUI for your Book Recommender")
    st.error("Artifacts not found. Please place preprocessed pickles in `artifacts/` or raw CSVs in `data/`.")

Expected picks: book_name.pkl, book_pivot.pkl, final_rating.pkl.
Or place ("BX-Books.csv and BX-Book-Ratings.csv in `data/`.")
    st.stop()

# Try to load BX-Books.csv to extract metadata (author, images)
books_meta = None
if BOOKS_CSV.exists():
    try:
        books_meta = pd.read_csv(BOOKS_CSV, sep=';', encoding='latin-1', low_memory=False)
        books_meta.columns = [c.strip() for c in books_meta.columns]
    except Exception:
        try:
            books_meta = pd.read_csv(BOOKS_CSV, encoding='latin-1', low_memory=False)
            books_meta.columns = [c.strip() for c in books_meta.columns]
        except Exception:
            books_meta = None

# Helper to get metadata row for a title
def get_meta_for_title(title):
    if books_meta is None:
        return {"author":"Unknown","image":PLACEHOLDER}
    # expected columns
    title_col = None
    author_col = None
    image_col = None
    for c in books_meta.columns:
        lc = c.lower()
        if 'title' in lc:
            title_col = c
        if 'author' in lc:
            author_col = c
        if 'image' in lc or 'url' in lc:
            image_col = c
    if title_col is None:
        return {"author":"Unknown","image":PLACEHOLDER}
    row = books_meta[books_meta[title_col].astype(str).str.strip().str.lower() == title.strip().lower()]
    if row.shape[0] == 0:
        # try fuzzy match by substring
        row = books_meta[books_meta[title_col].astype(str).str.lower().str.contains(title.strip().lower())]
    if row.shape[0] == 0:
        return {"author":"Unknown","image":PLACEHOLDER}
    r = row.iloc[0]
    author = r[author_col] if author_col and pd.notnull(r[author_col]) else "Unknown"
    img = r[image_col] if image_col and pd.notnull(r[image_col]) else PLACEHOLDER
    return {"author":str(author), "image":img}

# ----- UI -----
st.set_page_config(page_title="BookFlix", layout="wide")
st.markdown("<h1 style='text-align:center'>ðŸ“š BookFlix</h1>", unsafe_allow_html=True)
st.markdown("#### A Netflix-style interface for your Book Recommendation System")

# Sidebar
with st.sidebar:
    st.title("Controls")
    q = st.text_input("Search books or authors")
    rec_k = st.slider("Recs per row", 1, 10, 5)
    show_top = st.checkbox("Show Top Rated", value=True)
    show_trending = st.checkbox("Show Trending", value=True)
    selected = st.selectbox("Pick a book for recommendations", options=sorted(book_names))

# Search results
st.subheader("Search")
if q:
    matches = [t for t in book_names if q.lower() in t.lower()]
    if len(matches) == 0:
        st.info("No matches found")
    else:
        cols = st.columns(5)
        for i, t in enumerate(matches[:20]):
            c = cols[i % 5]
            meta = get_meta_for_title(t)
            img = try_fetch_image(meta['image'])
            if img is not None:
                c.image(img, use_column_width=True)
            else:
                c.image(meta['image'] if isinstance(meta['image'], str) else PLACEHOLDER, use_column_width=True)
            c.markdown(f"**{t}**")
            c.caption(meta['author'])

st.markdown("---")

# Top Rated row
if show_top and final_rating is not None:
    st.subheader("Top Rated")
    top_df = final_rating.sort_values(['avg_rating','num_rating'], ascending=False).head(20)
    cols = st.columns(5)
    for i, t in enumerate(top_df['title'].tolist()[:15]):
        c = cols[i % 5]
        meta = get_meta_for_title(t)
        img = try_fetch_image(meta['image'])
        if img is not None:
            c.image(img, use_column_width=True)
        else:
            c.image(meta['image'] if isinstance(meta['image'], str) else PLACEHOLDER, use_column_width=True)
        c.markdown(f"**{t}**")
        c.caption(meta['author'])

# Trending row
if show_trending and final_rating is not None:
    st.subheader("Trending")
    trending = final_rating.sort_values('num_rating', ascending=False).head(20)
    cols = st.columns(5)
    for i, t in enumerate(trending['title'].tolist()[:15]):
        c = cols[i % 5]
        meta = get_meta_for_title(t)
        img = try_fetch_image(meta['image'])
        if img is not None:
            c.image(img, use_column_width=True)
        else:
            c.image(meta['image'] if isinstance(meta['image'], str) else PLACEHOLDER, use_column_width=True)
        c.markdown(f"**{t}**")
        c.caption(meta['author'])

st.markdown("---")

st.subheader(f"Recommendations based on: {selected}")
# First try model.pkl
if model is not None:
    recs = recommend_with_knn(selected, model, pivot, k=rec_k)
elif sim_matrix is not None:
    recs = recommend_from_similarity(selected, sim_matrix, pivot, k=rec_k)
else:
    # fallback: compute simple cosine similarity on the fly (may be slow)
    try:
        sim_tmp = cosine_similarity(pivot.T)
        recs = recommend_from_similarity(selected, sim_tmp, pivot, k=rec_k)
    except Exception:
        recs = []

if not recs:
    st.info("No recommendations available for this title.")
else:
    cols = st.columns(rec_k)
    for i, t in enumerate(recs):
        c = cols[i]
        meta = get_meta_for_title(t)
        img = try_fetch_image(meta['image'])
        if img is not None:
            c.image(img, use_column_width=True)
        else:
            c.image(meta['image'] if isinstance(meta['image'], str) else PLACEHOLDER, use_column_width=True)
            st.markdown(f"**{t}**")
            c.caption(meta['author'])

st.markdown("---")
st.caption("Built from your Book Recommendation project â€” BookFlix")

# -------------------- Run notes --------------------
# To run the app locally:
# 1. Place your BX CSV files in ./data/ (BX-Books.csv and BX-Book-Ratings.csv)
# 2. pip install -r requirements.txt  (streamlit, scikit-learn, pandas, pillow, requests)
# 3. streamlit run app.py
